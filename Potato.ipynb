{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "authorship_tag": "ABX9TyOzfIlacs7e00PGxHzcEW7C",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/3S2/Potato-Disease-Classification-CNN-Model/blob/main/Potato.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FZyj7m08HNkf",
        "outputId": "6770a795-0ef9-4206-99b3-811d99a3809e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Lo"
      ],
      "metadata": {
        "id": "PKLdQQPqHQO5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Mount Google Drive (Optional)\n"
      ],
      "metadata": {
        "id": "iEvaCv9WHi0G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n"
      ],
      "metadata": {
        "id": "265bDYbnHp2s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Base dataset directory\n",
        "base_dir = \"/content/drive/MyDrive/POTATO\"  # Replace with your dataset path\n",
        "\n",
        "# Verify the directory exists\n",
        "assert os.path.exists(base_dir), f\"Dataset not found at {base_dir}\"\n",
        "print(f\"Dataset found at {base_dir}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a1parJH5HsYO",
        "outputId": "ecbf562f-5cb9-40f1-a9c1-74b806b2949e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset found at /content/drive/MyDrive/POTATO\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "from PIL import Image\n",
        "\n",
        "# Define dataset paths\n",
        "base_dir = \"/content/drive/MyDrive/POTATO\"  # Update to your tomato dataset path\n",
        "train_dir = os.path.join(base_dir, \"train\")\n",
        "validation_dir = os.path.join(base_dir, \"validation\")\n",
        "\n",
        "# Verify the dataset exists\n",
        "if not os.path.exists(base_dir):\n",
        "    raise FileNotFoundError(f\"Dataset not found at {base_dir}\")\n",
        "else:\n",
        "    print(f\"Dataset found at {base_dir}\")\n",
        "\n",
        "# Check and clean images\n",
        "def verify_images(directory):\n",
        "    invalid_files = []\n",
        "    for root, _, files in os.walk(directory):\n",
        "        for file in files:\n",
        "            file_path = os.path.join(root, file)\n",
        "            try:\n",
        "                img = Image.open(file_path)\n",
        "                img.verify()  # Check if image is corrupted\n",
        "            except Exception as e:\n",
        "                print(f\"Removing corrupted image: {file_path}\")\n",
        "                os.remove(file_path)\n",
        "                invalid_files.append(file_path)\n",
        "    return invalid_files\n",
        "\n",
        "# Verify train and validation sets\n",
        "print(\"Verifying training images...\")\n",
        "invalid_train_files = verify_images(train_dir)\n",
        "print(f\"Invalid files in training: {len(invalid_train_files)}\")\n",
        "\n",
        "print(\"Verifying validation images...\")\n",
        "invalid_val_files = verify_images(validation_dir)\n",
        "print(f\"Invalid files in validation: {len(invalid_val_files)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3uZrrWL8IIOj",
        "outputId": "b7fe7f52-006e-45d6-960f-2c8e40055669"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset found at /content/drive/MyDrive/POTATO\n",
            "Verifying training images...\n",
            "Invalid files in training: 0\n",
            "Verifying validation images...\n",
            "Invalid files in validation: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import shutil\n",
        "\n",
        "# Define the source and destination paths\n",
        "base_dir = \"/content/drive/MyDrive/\"  # Update to your dataset path\n",
        "dataset_dir = os.path.join(base_dir, \"POTATO\")\n",
        "train_dir = os.path.join(base_dir, \"train\")\n",
        "val_dir = os.path.join(base_dir, \"validation\")\n",
        "test_dir = os.path.join(base_dir, \"test\")\n",
        "\n",
        "# Create train, validation, and test directories\n",
        "for split_dir in [train_dir, val_dir, test_dir]:\n",
        "    for class_name in [\"early_blight\", \"late_blight\", \"healthy\"]:\n",
        "        os.makedirs(os.path.join(split_dir, class_name), exist_ok=True)\n",
        "\n",
        "# Define split ratios\n",
        "train_ratio = 0.7\n",
        "val_ratio = 0.2\n",
        "test_ratio = 0.1\n",
        "\n",
        "# Function to split the dataset\n",
        "def split_dataset(class_name):\n",
        "    source = os.path.join(dataset_dir, class_name)\n",
        "    images = os.listdir(source)\n",
        "    random.shuffle(images)\n",
        "\n",
        "    train_split = int(len(images) * train_ratio)\n",
        "    val_split = int(len(images) * (train_ratio + val_ratio))\n",
        "\n",
        "    for i, img in enumerate(images):\n",
        "        src_path = os.path.join(source, img)\n",
        "        if i < train_split:\n",
        "            dest_path = os.path.join(train_dir, class_name, img)\n",
        "        elif i < val_split:\n",
        "            dest_path = os.path.join(val_dir, class_name, img)\n",
        "        else:\n",
        "            dest_path = os.path.join(test_dir, class_name, img)\n",
        "\n",
        "        shutil.copy(src_path, dest_path)\n",
        "\n",
        "# Apply splitting to each class\n",
        "for class_name in [\"early_blight\", \"late_blight\", \"healthy\"]:\n",
        "    split_dataset(class_name)\n",
        "\n",
        "print(\"Dataset split into train, validation, and test sets!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "2z4dz6HqNDMR",
        "outputId": "cbf6993a-2d87-4021-c976-9a98bd812cf8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/drive/MyDrive/POTATO/early_blight'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-0d5dd4dc2743>\u001b[0m in \u001b[0;36m<cell line: 43>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;31m# Apply splitting to each class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mclass_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"early_blight\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"late_blight\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"healthy\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m     \u001b[0msplit_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Dataset split into train, validation, and test sets!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-0d5dd4dc2743>\u001b[0m in \u001b[0;36msplit_dataset\u001b[0;34m(class_name)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msplit_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0msource\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/POTATO/early_blight'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "# Function to verify and summarize dataset structure\n",
        "def check_dataset_structure(base_path):\n",
        "    if not os.path.exists(base_path):\n",
        "        print(f\"The dataset path {base_path} does not exist.\")\n",
        "        return None\n",
        "\n",
        "    dataset_summary = {}\n",
        "    print(f\"Checking dataset structure in: {base_path}\\n\")\n",
        "    for folder_name in os.listdir(base_path):\n",
        "        folder_path = os.path.join(base_path, folder_name)\n",
        "        if os.path.isdir(folder_path):  # Only process directories\n",
        "            image_files = [\n",
        "                file for file in os.listdir(folder_path)\n",
        "                if os.path.isfile(os.path.join(folder_path, file))\n",
        "            ]\n",
        "            num_images = len(image_files)\n",
        "            dataset_summary[folder_name] = num_images\n",
        "\n",
        "            # Verify image integrity\n",
        "            invalid_images = []\n",
        "            for image_file in image_files:\n",
        "                image_path = os.path.join(folder_path, image_file)\n",
        "                try:\n",
        "                    img = Image.open(image_path)\n",
        "                    img.verify()  # Check if the image can be opened\n",
        "                except Exception as e:\n",
        "                    invalid_images.append(image_file)\n",
        "                    os.remove(image_path)  # Remove corrupted file\n",
        "                    print(f\"Removed corrupted image: {image_path}\")\n",
        "\n",
        "            print(f\"Class '{folder_name}': {num_images - len(invalid_images)} valid images, {len(invalid_images)} invalid images removed.\")\n",
        "\n",
        "    return dataset_summary\n",
        "\n",
        "# Base dataset directory\n",
        "base_dir = \"/content/drive/MyDrive/OrganizedDataset\"  # Update with your dataset path\n",
        "\n",
        "# Summarize dataset\n",
        "dataset_summary = check_dataset_structure(base_dir)\n",
        "\n",
        "# Display the summary\n",
        "if dataset_summary:\n",
        "    print(\"\\nDataset Summary:\")\n",
        "    for folder, count in dataset_summary.items():\n",
        "        print(f\"Class '{folder}': {count} images\")\n",
        "else:\n",
        "    print(\"\\nNo valid dataset structure found.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d39AWhveNWXe",
        "outputId": "88d76a76-dc9a-43c4-89f1-1dc58df45a8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checking dataset structure in: /content/drive/MyDrive/OrganizedDataset\n",
            "\n",
            "Class 'train': 0 valid images, 0 invalid images removed.\n",
            "Class 'validation': 0 valid images, 0 invalid images removed.\n",
            "Class 'test': 0 valid images, 0 invalid images removed.\n",
            "\n",
            "Dataset Summary:\n",
            "Class 'train': 0 images\n",
            "Class 'validation': 0 images\n",
            "Class 'test': 0 images\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def check_images_in_directory(base_path):\n",
        "    for root, dirs, files in os.walk(base_path):\n",
        "        print(f\"Checking: {root}\")\n",
        "        print(f\" - Subdirectories: {dirs}\")\n",
        "        print(f\" - Number of files: {len(files)}\\n\")\n",
        "\n",
        "# Check the dataset directory\n",
        "check_images_in_directory(base_dir)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S1JxXgSmTEEZ",
        "outputId": "dd920a10-d0fb-499e-d360-99d8cd522a35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checking: /content/drive/MyDrive/OrganizedDataset\n",
            " - Subdirectories: ['train', 'validation', 'test', 'augmented']\n",
            " - Number of files: 0\n",
            "\n",
            "Checking: /content/drive/MyDrive/OrganizedDataset/train\n",
            " - Subdirectories: ['Potato___Late_blight', 'Potato___Early_blight', 'Potato___healthy']\n",
            " - Number of files: 0\n",
            "\n",
            "Checking: /content/drive/MyDrive/OrganizedDataset/train/Potato___Late_blight\n",
            " - Subdirectories: []\n",
            " - Number of files: 700\n",
            "\n",
            "Checking: /content/drive/MyDrive/OrganizedDataset/train/Potato___Early_blight\n",
            " - Subdirectories: []\n",
            " - Number of files: 700\n",
            "\n",
            "Checking: /content/drive/MyDrive/OrganizedDataset/train/Potato___healthy\n",
            " - Subdirectories: []\n",
            " - Number of files: 689\n",
            "\n",
            "Checking: /content/drive/MyDrive/OrganizedDataset/validation\n",
            " - Subdirectories: ['Potato___Late_blight', 'Potato___Early_blight', 'Potato___healthy']\n",
            " - Number of files: 0\n",
            "\n",
            "Checking: /content/drive/MyDrive/OrganizedDataset/validation/Potato___Late_blight\n",
            " - Subdirectories: []\n",
            " - Number of files: 150\n",
            "\n",
            "Checking: /content/drive/MyDrive/OrganizedDataset/validation/Potato___Early_blight\n",
            " - Subdirectories: []\n",
            " - Number of files: 150\n",
            "\n",
            "Checking: /content/drive/MyDrive/OrganizedDataset/validation/Potato___healthy\n",
            " - Subdirectories: []\n",
            " - Number of files: 23\n",
            "\n",
            "Checking: /content/drive/MyDrive/OrganizedDataset/test\n",
            " - Subdirectories: ['Potato___Late_blight', 'Potato___Early_blight', 'Potato___healthy']\n",
            " - Number of files: 0\n",
            "\n",
            "Checking: /content/drive/MyDrive/OrganizedDataset/test/Potato___Late_blight\n",
            " - Subdirectories: []\n",
            " - Number of files: 151\n",
            "\n",
            "Checking: /content/drive/MyDrive/OrganizedDataset/test/Potato___Early_blight\n",
            " - Subdirectories: []\n",
            " - Number of files: 151\n",
            "\n",
            "Checking: /content/drive/MyDrive/OrganizedDataset/test/Potato___healthy\n",
            " - Subdirectories: []\n",
            " - Number of files: 23\n",
            "\n",
            "Checking: /content/drive/MyDrive/OrganizedDataset/augmented\n",
            " - Subdirectories: ['Potato___healthy']\n",
            " - Number of files: 0\n",
            "\n",
            "Checking: /content/drive/MyDrive/OrganizedDataset/augmented/Potato___healthy\n",
            " - Subdirectories: []\n",
            " - Number of files: 0\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
        "from PIL import Image\n",
        "\n",
        "# Define paths\n",
        "healthy_dir = \"/content/drive/MyDrive/OrganizedDataset/train/Potato___healthy\"\n",
        "augment_dir = \"/content/drive/MyDrive/OrganizedDataset/augmented/Potato___healthy\"  # Augmented output directory\n",
        "os.makedirs(augment_dir, exist_ok=True)\n",
        "\n",
        "# Augmentation setup\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode=\"nearest\"\n",
        ")\n",
        "\n",
        "# Augment images\n",
        "def augment_images(input_dir, output_dir, target_count):\n",
        "    images = os.listdir(input_dir)\n",
        "    current_count = len(images)\n",
        "    augmented_count = 0\n",
        "\n",
        "    for img_name in images:\n",
        "        if augmented_count >= target_count - current_count:\n",
        "            break\n",
        "\n",
        "        img_path = os.path.join(input_dir, img_name)\n",
        "        img = load_img(img_path)  # Load image\n",
        "        img_array = img_to_array(img)  # Convert to array\n",
        "        img_array = img_array.reshape((1,) + img_array.shape)  # Reshape for generator\n",
        "\n",
        "        # Generate and save augmented images\n",
        "        for batch in datagen.flow(img_array, batch_size=1, save_to_dir=output_dir,\n",
        "                                  save_prefix=\"aug\", save_format=\"jpeg\"):\n",
        "            augmented_count += 1\n",
        "            if augmented_count >= target_count - current_count:\n",
        "                break\n",
        "\n",
        "# Desired count after augmentation\n",
        "target_image_count = 700  # Same as the other classes in the training set\n",
        "\n",
        "# Augment images\n",
        "augment_images(healthy_dir, augment_dir, target_image_count)\n",
        "\n",
        "print(f\"Augmentation complete. Augmented images saved in: {augment_dir}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5LpNZs0lTx4b",
        "outputId": "93cdc02b-ee18-42b1-9158-eea2fab07213"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Augmentation complete. Augmented images saved in: /content/drive/MyDrive/OrganizedDataset/augmented/Potato___healthy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "# Paths\n",
        "augmented_dir = \"/content/drive/MyDrive/OrganizedDataset/augmented/Potato___healthy\"\n",
        "train_healthy_dir = \"/content/drive/MyDrive/OrganizedDataset/train/Potato___healthy\"\n",
        "\n",
        "# Move augmented images to the training folder\n",
        "augmented_images = os.listdir(augmented_dir)\n",
        "for img_name in augmented_images:\n",
        "    src_path = os.path.join(augmented_dir, img_name)\n",
        "    dest_path = os.path.join(train_healthy_dir, img_name)\n",
        "    shutil.move(src_path, dest_path)\n",
        "\n",
        "print(f\"Moved {len(augmented_images)} augmented images to the training folder.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0qGRueNiUEkr",
        "outputId": "e3f2c68f-5541-4138-c996-f3c771e05a3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moved 583 augmented images to the training folder.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "def remove_corrupted_images(directory):\n",
        "    corrupted_files = []\n",
        "    for root, _, files in os.walk(directory):\n",
        "        for file in files:\n",
        "            file_path = os.path.join(root, file)\n",
        "            try:\n",
        "                img = Image.open(file_path)\n",
        "                img.verify()  # Verify if the image is valid\n",
        "            except Exception as e:\n",
        "                print(f\"Corrupted image found and removed: {file_path}\")\n",
        "                corrupted_files.append(file_path)\n",
        "                os.remove(file_path)  # Remove the corrupted file\n",
        "    return corrupted_files\n",
        "\n",
        "# Dataset directory\n",
        "base_dir = \"/content/drive/MyDrive/OrganizedDataset\"  # Update with your dataset path\n",
        "\n",
        "# Remove corrupted images\n",
        "corrupted_files = remove_corrupted_images(base_dir)\n",
        "print(f\"\\nTotal corrupted images removed: {len(corrupted_files)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tgSPC9K2UWhk",
        "outputId": "4d95f00f-4675-40e9-8f7c-ea087e56cfa8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Total corrupted images removed: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import hashlib\n",
        "\n",
        "def find_and_remove_duplicates(directory):\n",
        "    file_hashes = {}\n",
        "    duplicate_files = []\n",
        "\n",
        "    for root, _, files in os.walk(directory):\n",
        "        for file in files:\n",
        "            file_path = os.path.join(root, file)\n",
        "            try:\n",
        "                # Compute hash of the image\n",
        "                with open(file_path, \"rb\") as f:\n",
        "                    file_hash = hashlib.md5(f.read()).hexdigest()\n",
        "\n",
        "                if file_hash in file_hashes:\n",
        "                    print(f\"Duplicate image found and removed: {file_path}\")\n",
        "                    duplicate_files.append(file_path)\n",
        "                    os.remove(file_path)  # Remove duplicate\n",
        "                else:\n",
        "                    file_hashes[file_hash] = file_path\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing file: {file_path}, {e}\")\n",
        "\n",
        "    return duplicate_files\n",
        "\n",
        "# Remove duplicate images\n",
        "duplicate_files = find_and_remove_duplicates(base_dir)\n",
        "print(f\"\\nTotal duplicate images removed: {len(duplicate_files)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lV1ipBhnVGIA",
        "outputId": "8ec1e1b2-5819-43a2-d773-0c9b5ca697b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Duplicate image found and removed: /content/drive/MyDrive/OrganizedDataset/test/Potato___Late_blight/Copy of 0acdc2b2-0dde-4073-8542-6fca275ab974___RS_LB 4857.JPG\n",
            "\n",
            "Total duplicate images removed: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import EfficientNetB0\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "# Define image dimensions and number of classes\n",
        "IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS = 224, 224, 3\n",
        "NUM_CLASSES = 3  # Update based on your dataset\n",
        "\n",
        "# Load the EfficientNetB0 model without the top layer\n",
        "efficientnet_base = EfficientNetB0(\n",
        "    include_top=False,  # Exclude the fully connected layer\n",
        "    weights='imagenet',  # Pre-trained on ImageNet\n",
        "    input_shape=(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS)\n",
        ")\n",
        "\n",
        "# Freeze the base model's layers\n",
        "efficientnet_base.trainable = False\n",
        "\n",
        "# Add custom layers for your dataset\n",
        "efficientnet_model = models.Sequential([\n",
        "    efficientnet_base,\n",
        "    layers.GlobalAveragePooling2D(),\n",
        "    layers.Dense(256, activation='relu'),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(NUM_CLASSES, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "efficientnet_model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Display model summary\n",
        "efficientnet_model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "id": "qQtAlAAmVJvx",
        "outputId": "a8cb0e40-6e2b-47b2-d5dc-3959315a58a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n",
            "\u001b[1m16705208/16705208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ efficientnetb0 (\u001b[38;5;33mFunctional\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m1280\u001b[0m)          │       \u001b[38;5;34m4,049,571\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ global_average_pooling2d             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)             │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │         \u001b[38;5;34m327,936\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)                   │             \u001b[38;5;34m771\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ efficientnetb0 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)          │       <span style=\"color: #00af00; text-decoration-color: #00af00\">4,049,571</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ global_average_pooling2d             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)             │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">327,936</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">771</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,378,278\u001b[0m (16.70 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,378,278</span> (16.70 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m328,707\u001b[0m (1.25 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">328,707</span> (1.25 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m4,049,571\u001b[0m (15.45 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,049,571</span> (15.45 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Data directories\n",
        "train_dir = \"/content/drive/MyDrive/OrganizedDataset/train\"\n",
        "val_dir = \"/content/drive/MyDrive/OrganizedDataset/validation\"\n",
        "\n",
        "# Data augmentation and preprocessing\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1.0/255,  # Normalize pixel values\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "\n",
        "val_datagen = ImageDataGenerator(rescale=1.0/255)\n",
        "\n",
        "# Load images from directories\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "val_generator = val_datagen.flow_from_directory(\n",
        "    val_dir,\n",
        "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NZvGasONYxnw",
        "outputId": "071fbad2-1a69-4429-fc5c-6da380f93023"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2089 images belonging to 3 classes.\n",
            "Found 323 images belonging to 3 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Train EfficientNet model\n",
        "efficientnet_history = efficientnet_model.fit(\n",
        "    train_generator,\n",
        "    epochs=10,\n",
        "    validation_data=val_generator,\n",
        "    callbacks=[\n",
        "        tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3),\n",
        "        tf.keras.callbacks.ModelCheckpoint(\"efficientnet_best.keras\", save_best_only=True)\n",
        "    ]\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-zQ31DKGY2k0",
        "outputId": "f91d1fed-9e4a-4d8f-cd98-0084b99d58bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m296s\u001b[0m 4s/step - accuracy: 0.3040 - loss: 1.1074 - val_accuracy: 0.4644 - val_loss: 1.0599\n",
            "Epoch 2/10\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m302s\u001b[0m 4s/step - accuracy: 0.3077 - loss: 1.1129 - val_accuracy: 0.0712 - val_loss: 1.1177\n",
            "Epoch 3/10\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m272s\u001b[0m 4s/step - accuracy: 0.3345 - loss: 1.1065 - val_accuracy: 0.0712 - val_loss: 1.1226\n",
            "Epoch 4/10\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m330s\u001b[0m 4s/step - accuracy: 0.3435 - loss: 1.1006 - val_accuracy: 0.0712 - val_loss: 1.1071\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)\n"
      ],
      "metadata": {
        "id": "NaIRuUS9Y4fc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "efficientnet_base.trainable = True\n"
      ],
      "metadata": {
        "id": "IN4-s8PoePfs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adjust the learning rate\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
        "\n",
        "# Compile the model with the new optimizer\n",
        "efficientnet_model.compile(\n",
        "    optimizer=optimizer,\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Unfreeze the base model for fine-tuning\n",
        "efficientnet_base.trainable = True\n",
        "\n",
        "# Train the model again\n",
        "efficientnet_history = efficientnet_model.fit(\n",
        "    train_generator,\n",
        "    epochs=20,  # Train for more epochs\n",
        "    validation_data=val_generator,\n",
        "    callbacks=[\n",
        "        tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True),\n",
        "        tf.keras.callbacks.ModelCheckpoint(\"efficientnet_best.keras\", save_best_only=True)\n",
        "    ]\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K4kJ_3CbeQ4R",
        "outputId": "2fb20079-b97e-4aee-8bf0-1738c94c8b5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m49/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m3:32\u001b[0m 12s/step - accuracy: 0.6391 - loss: 0.7950"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rNtX9GDHeTB0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}